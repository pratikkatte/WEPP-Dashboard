{"version":3,"file":"tabixIndexedFile-BiRfT466.js","sources":["../node_modules/@gmod/tabix/esm/util.js","../node_modules/@gmod/tabix/esm/virtualOffset.js","../node_modules/@gmod/tabix/esm/chunk.js","../node_modules/@gmod/tabix/esm/indexFile.js","../node_modules/@gmod/tabix/esm/tbi.js","../node_modules/@gmod/tabix/esm/csi.js","../node_modules/@gmod/tabix/esm/tabixIndexedFile.js"],"sourcesContent":["export function longToNumber(long) {\n    if (long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n        long.lessThan(Number.MIN_SAFE_INTEGER)) {\n        throw new Error('integer overflow');\n    }\n    return long.toNumber();\n}\nclass AbortError extends Error {\n}\n/**\n * Properly check if the given AbortSignal is aborted. Per the standard, if the\n * signal reads as aborted, this function throws either a DOMException\n * AbortError, or a regular error with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted`\n * attribute\n *\n * @returns nothing\n */\nexport function checkAbortSignal(signal) {\n    if (!signal) {\n        return;\n    }\n    if (signal.aborted) {\n        if (typeof DOMException !== 'undefined') {\n            throw new DOMException('aborted', 'AbortError');\n        }\n        else {\n            const e = new AbortError('aborted');\n            e.code = 'ERR_ABORTED';\n            throw e;\n        }\n    }\n}\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nexport async function abortBreakPoint(signal) {\n    await Promise.resolve();\n    checkAbortSignal(signal);\n}\nexport function canMergeBlocks(chunk1, chunk2) {\n    return (chunk2.minv.blockPosition - chunk1.maxv.blockPosition < 65000 &&\n        chunk2.maxv.blockPosition - chunk1.minv.blockPosition < 5000000);\n}\nexport function optimizeChunks(chunks, lowest) {\n    const mergedChunks = [];\n    let lastChunk = null;\n    if (chunks.length === 0) {\n        return chunks;\n    }\n    chunks.sort(function (c0, c1) {\n        const dif = c0.minv.blockPosition - c1.minv.blockPosition;\n        return dif !== 0 ? dif : c0.minv.dataPosition - c1.minv.dataPosition;\n    });\n    chunks.forEach(chunk => {\n        if (!lowest || chunk.maxv.compareTo(lowest) > 0) {\n            if (lastChunk === null) {\n                mergedChunks.push(chunk);\n                lastChunk = chunk;\n            }\n            else {\n                if (canMergeBlocks(lastChunk, chunk)) {\n                    if (chunk.maxv.compareTo(lastChunk.maxv) > 0) {\n                        lastChunk.maxv = chunk.maxv;\n                    }\n                }\n                else {\n                    mergedChunks.push(chunk);\n                    lastChunk = chunk;\n                }\n            }\n        }\n    });\n    return mergedChunks;\n}\n//# sourceMappingURL=util.js.map","export default class VirtualOffset {\n    constructor(blockPosition, dataPosition) {\n        this.blockPosition = blockPosition; // < offset of the compressed data block\n        this.dataPosition = dataPosition; // < offset into the uncompressed data\n    }\n    toString() {\n        return `${this.blockPosition}:${this.dataPosition}`;\n    }\n    compareTo(b) {\n        return (this.blockPosition - b.blockPosition || this.dataPosition - b.dataPosition);\n    }\n}\nexport function fromBytes(bytes, offset = 0, bigendian = false) {\n    if (bigendian) {\n        throw new Error('big-endian virtual file offsets not implemented');\n    }\n    return new VirtualOffset(bytes[offset + 7] * 0x10000000000 +\n        bytes[offset + 6] * 0x100000000 +\n        bytes[offset + 5] * 0x1000000 +\n        bytes[offset + 4] * 0x10000 +\n        bytes[offset + 3] * 0x100 +\n        bytes[offset + 2], (bytes[offset + 1] << 8) | bytes[offset]);\n}\n//# sourceMappingURL=virtualOffset.js.map","// little class representing a chunk in the index\nexport default class Chunk {\n    constructor(minv, maxv, bin, fetchedSize = undefined) {\n        this.minv = minv;\n        this.maxv = maxv;\n        this.bin = bin;\n        this._fetchedSize = fetchedSize;\n    }\n    toUniqueString() {\n        return `${this.minv}..${this.maxv} (bin ${this.bin}, fetchedSize ${this.fetchedSize()})`;\n    }\n    toString() {\n        return this.toUniqueString();\n    }\n    compareTo(b) {\n        return (this.minv.compareTo(b.minv) ||\n            this.maxv.compareTo(b.maxv) ||\n            this.bin - b.bin);\n    }\n    fetchedSize() {\n        if (this._fetchedSize !== undefined) {\n            return this._fetchedSize;\n        }\n        return this.maxv.blockPosition + (1 << 16) - this.minv.blockPosition;\n    }\n}\n//# sourceMappingURL=chunk.js.map","export default class IndexFile {\n    constructor({ filehandle, renameRefSeqs = (n) => n, }) {\n        this.filehandle = filehandle;\n        this.renameRefSeq = renameRefSeqs;\n    }\n    async getMetadata(opts = {}) {\n        const { indices: _indices, ...rest } = await this.parse(opts);\n        return rest;\n    }\n    _findFirstData(currentFdl, virtualOffset) {\n        if (currentFdl) {\n            return currentFdl.compareTo(virtualOffset) > 0\n                ? virtualOffset\n                : currentFdl;\n        }\n        else {\n            return virtualOffset;\n        }\n    }\n    async parse(opts = {}) {\n        if (!this.parseP) {\n            this.parseP = this._parse(opts).catch((e) => {\n                this.parseP = undefined;\n                throw e;\n            });\n        }\n        return this.parseP;\n    }\n    async hasRefSeq(seqId, opts = {}) {\n        var _a;\n        const idx = await this.parse(opts);\n        return !!((_a = idx.indices[seqId]) === null || _a === void 0 ? void 0 : _a.binIndex);\n    }\n}\n//# sourceMappingURL=indexFile.js.map","import Long from 'long';\nimport VirtualOffset, { fromBytes } from './virtualOffset';\nimport Chunk from './chunk';\nimport { unzip } from '@gmod/bgzf-filehandle';\nimport { longToNumber, optimizeChunks, checkAbortSignal } from './util';\nimport IndexFile from './indexFile';\nconst TBI_MAGIC = 21578324; // TBI\\1\nconst TAD_LIDX_SHIFT = 14;\n/**\n * calculate the list of bins that may overlap with region [beg,end)\n * (zero-based half-open)\n */\nfunction reg2bins(beg, end) {\n    beg += 1; // < convert to 1-based closed\n    end -= 1;\n    return [\n        [0, 0],\n        [1 + (beg >> 26), 1 + (end >> 26)],\n        [9 + (beg >> 23), 9 + (end >> 23)],\n        [73 + (beg >> 20), 73 + (end >> 20)],\n        [585 + (beg >> 17), 585 + (end >> 17)],\n        [4681 + (beg >> 14), 4681 + (end >> 14)],\n    ];\n}\nexport default class TabixIndex extends IndexFile {\n    async lineCount(refName, opts = {}) {\n        const indexData = await this.parse(opts);\n        const refId = indexData.refNameToId[refName];\n        if (refId === undefined) {\n            return -1;\n        }\n        const idx = indexData.indices[refId];\n        if (!idx) {\n            return -1;\n        }\n        const { stats } = indexData.indices[refId];\n        if (stats) {\n            return stats.lineCount;\n        }\n        return -1;\n    }\n    // fetch and parse the index\n    async _parse(opts = {}) {\n        const buf = await this.filehandle.readFile(opts);\n        const bytes = await unzip(buf);\n        checkAbortSignal(opts.signal);\n        // check TBI magic numbers\n        if (bytes.readUInt32LE(0) !== TBI_MAGIC /* \"TBI\\1\" */) {\n            throw new Error('Not a TBI file');\n            // TODO: do we need to support big-endian TBI files?\n        }\n        // number of reference sequences in the index\n        const refCount = bytes.readInt32LE(4);\n        const formatFlags = bytes.readInt32LE(8);\n        const coordinateType = formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed';\n        const formatOpts = {\n            0: 'generic',\n            1: 'SAM',\n            2: 'VCF',\n        };\n        const format = formatOpts[formatFlags & 0xf];\n        if (!format) {\n            throw new Error(`invalid Tabix preset format flags ${formatFlags}`);\n        }\n        const columnNumbers = {\n            ref: bytes.readInt32LE(12),\n            start: bytes.readInt32LE(16),\n            end: bytes.readInt32LE(20),\n        };\n        const metaValue = bytes.readInt32LE(24);\n        const depth = 5;\n        const maxBinNumber = ((1 << ((depth + 1) * 3)) - 1) / 7;\n        const maxRefLength = 2 ** (14 + depth * 3);\n        const metaChar = metaValue ? String.fromCharCode(metaValue) : null;\n        const skipLines = bytes.readInt32LE(28);\n        // read sequence dictionary\n        const nameSectionLength = bytes.readInt32LE(32);\n        const { refNameToId, refIdToName } = this._parseNameBytes(bytes.slice(36, 36 + nameSectionLength));\n        // read the indexes for each reference sequence\n        let currOffset = 36 + nameSectionLength;\n        let firstDataLine;\n        const indices = new Array(refCount).fill(0).map(() => {\n            // the binning index\n            const binCount = bytes.readInt32LE(currOffset);\n            currOffset += 4;\n            const binIndex = {};\n            let stats;\n            for (let j = 0; j < binCount; j += 1) {\n                const bin = bytes.readUInt32LE(currOffset);\n                currOffset += 4;\n                if (bin > maxBinNumber + 1) {\n                    throw new Error('tabix index contains too many bins, please use a CSI index');\n                }\n                else if (bin === maxBinNumber + 1) {\n                    const chunkCount = bytes.readInt32LE(currOffset);\n                    currOffset += 4;\n                    if (chunkCount === 2) {\n                        stats = this.parsePseudoBin(bytes, currOffset);\n                    }\n                    currOffset += 16 * chunkCount;\n                }\n                else {\n                    const chunkCount = bytes.readInt32LE(currOffset);\n                    currOffset += 4;\n                    const chunks = new Array(chunkCount);\n                    for (let k = 0; k < chunkCount; k += 1) {\n                        const u = fromBytes(bytes, currOffset);\n                        const v = fromBytes(bytes, currOffset + 8);\n                        currOffset += 16;\n                        firstDataLine = this._findFirstData(firstDataLine, u);\n                        chunks[k] = new Chunk(u, v, bin);\n                    }\n                    binIndex[bin] = chunks;\n                }\n            }\n            // the linear index\n            const linearCount = bytes.readInt32LE(currOffset);\n            currOffset += 4;\n            const linearIndex = new Array(linearCount);\n            for (let k = 0; k < linearCount; k += 1) {\n                linearIndex[k] = fromBytes(bytes, currOffset);\n                currOffset += 8;\n                firstDataLine = this._findFirstData(firstDataLine, linearIndex[k]);\n            }\n            return { binIndex, linearIndex, stats };\n        });\n        return {\n            indices,\n            metaChar,\n            maxBinNumber,\n            maxRefLength,\n            skipLines,\n            firstDataLine,\n            columnNumbers,\n            coordinateType,\n            format,\n            refIdToName,\n            refNameToId,\n            maxBlockSize: 1 << 16,\n        };\n    }\n    parsePseudoBin(bytes, offset) {\n        const lineCount = longToNumber(Long.fromBytesLE(bytes.slice(offset + 16, offset + 24), true));\n        return { lineCount };\n    }\n    _parseNameBytes(namesBytes) {\n        let currRefId = 0;\n        let currNameStart = 0;\n        const refIdToName = [];\n        const refNameToId = {};\n        for (let i = 0; i < namesBytes.length; i += 1) {\n            if (!namesBytes[i]) {\n                if (currNameStart < i) {\n                    let refName = namesBytes.toString('utf8', currNameStart, i);\n                    refName = this.renameRefSeq(refName);\n                    refIdToName[currRefId] = refName;\n                    refNameToId[refName] = currRefId;\n                }\n                currNameStart = i + 1;\n                currRefId += 1;\n            }\n        }\n        return { refNameToId, refIdToName };\n    }\n    async blocksForRange(refName, min, max, opts = {}) {\n        if (min < 0) {\n            min = 0;\n        }\n        const indexData = await this.parse(opts);\n        const refId = indexData.refNameToId[refName];\n        if (refId === undefined) {\n            return [];\n        }\n        const ba = indexData.indices[refId];\n        if (!ba) {\n            return [];\n        }\n        const minOffset = ba.linearIndex.length\n            ? ba.linearIndex[min >> TAD_LIDX_SHIFT >= ba.linearIndex.length\n                ? ba.linearIndex.length - 1\n                : min >> TAD_LIDX_SHIFT]\n            : new VirtualOffset(0, 0);\n        if (!minOffset) {\n            console.warn('querying outside of possible tabix range');\n        }\n        // const { linearIndex, binIndex } = indexes\n        const overlappingBins = reg2bins(min, max); // List of bin #s that overlap min, max\n        const chunks = [];\n        // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n        for (const [start, end] of overlappingBins) {\n            for (let bin = start; bin <= end; bin++) {\n                if (ba.binIndex[bin]) {\n                    for (const c of ba.binIndex[bin]) {\n                        chunks.push(new Chunk(c.minv, c.maxv, bin));\n                    }\n                }\n            }\n        }\n        // Use the linear index to find minimum file position of chunks that could\n        // contain alignments in the region\n        const nintv = ba.linearIndex.length;\n        let lowest = null;\n        const minLin = Math.min(min >> 14, nintv - 1);\n        const maxLin = Math.min(max >> 14, nintv - 1);\n        for (let i = minLin; i <= maxLin; ++i) {\n            const vp = ba.linearIndex[i];\n            if (vp) {\n                if (!lowest || vp.compareTo(lowest) < 0) {\n                    lowest = vp;\n                }\n            }\n        }\n        return optimizeChunks(chunks, lowest);\n    }\n}\n//# sourceMappingURL=tbi.js.map","import Long from 'long';\nimport { unzip } from '@gmod/bgzf-filehandle';\nimport VirtualOffset, { fromBytes } from './virtualOffset';\nimport Chunk from './chunk';\nimport { longToNumber, optimizeChunks } from './util';\nimport IndexFile from './indexFile';\nconst CSI1_MAGIC = 21582659; // CSI\\1\nconst CSI2_MAGIC = 38359875; // CSI\\2\nfunction lshift(num, bits) {\n    return num * 2 ** bits;\n}\nfunction rshift(num, bits) {\n    return Math.floor(num / 2 ** bits);\n}\nexport default class CSI extends IndexFile {\n    constructor(args) {\n        super(args);\n        this.maxBinNumber = 0;\n        this.depth = 0;\n        this.minShift = 0;\n    }\n    async lineCount(refName, opts = {}) {\n        const indexData = await this.parse(opts);\n        const refId = indexData.refNameToId[refName];\n        if (refId === undefined) {\n            return -1;\n        }\n        const idx = indexData.indices[refId];\n        if (!idx) {\n            return -1;\n        }\n        const { stats } = indexData.indices[refId];\n        if (stats) {\n            return stats.lineCount;\n        }\n        return -1;\n    }\n    indexCov() {\n        throw new Error('CSI indexes do not support indexcov');\n    }\n    parseAuxData(bytes, offset) {\n        const formatFlags = bytes.readInt32LE(offset);\n        const coordinateType = formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed';\n        const format = { 0: 'generic', 1: 'SAM', 2: 'VCF' }[formatFlags & 0xf];\n        if (!format) {\n            throw new Error(`invalid Tabix preset format flags ${formatFlags}`);\n        }\n        const columnNumbers = {\n            ref: bytes.readInt32LE(offset + 4),\n            start: bytes.readInt32LE(offset + 8),\n            end: bytes.readInt32LE(offset + 12),\n        };\n        const metaValue = bytes.readInt32LE(offset + 16);\n        const metaChar = metaValue ? String.fromCharCode(metaValue) : null;\n        const skipLines = bytes.readInt32LE(offset + 20);\n        const nameSectionLength = bytes.readInt32LE(offset + 24);\n        const { refIdToName, refNameToId } = this._parseNameBytes(bytes.slice(offset + 28, offset + 28 + nameSectionLength));\n        return {\n            refIdToName,\n            refNameToId,\n            skipLines,\n            metaChar,\n            columnNumbers,\n            format,\n            coordinateType,\n        };\n    }\n    _parseNameBytes(namesBytes) {\n        let currRefId = 0;\n        let currNameStart = 0;\n        const refIdToName = [];\n        const refNameToId = {};\n        for (let i = 0; i < namesBytes.length; i += 1) {\n            if (!namesBytes[i]) {\n                if (currNameStart < i) {\n                    let refName = namesBytes.toString('utf8', currNameStart, i);\n                    refName = this.renameRefSeq(refName);\n                    refIdToName[currRefId] = refName;\n                    refNameToId[refName] = currRefId;\n                }\n                currNameStart = i + 1;\n                currRefId += 1;\n            }\n        }\n        return { refNameToId, refIdToName };\n    }\n    // fetch and parse the index\n    async _parse(opts = {}) {\n        const bytes = await unzip(await this.filehandle.readFile(opts));\n        // check TBI magic numbers\n        let csiVersion;\n        if (bytes.readUInt32LE(0) === CSI1_MAGIC) {\n            csiVersion = 1;\n        }\n        else if (bytes.readUInt32LE(0) === CSI2_MAGIC) {\n            csiVersion = 2;\n        }\n        else {\n            throw new Error('Not a CSI file');\n            // TODO: do we need to support big-endian CSI files?\n        }\n        this.minShift = bytes.readInt32LE(4);\n        this.depth = bytes.readInt32LE(8);\n        this.maxBinNumber = ((1 << ((this.depth + 1) * 3)) - 1) / 7;\n        const maxRefLength = 2 ** (this.minShift + this.depth * 3);\n        const auxLength = bytes.readInt32LE(12);\n        const aux = auxLength && auxLength >= 30\n            ? this.parseAuxData(bytes, 16)\n            : {\n                refIdToName: [],\n                refNameToId: {},\n                metaChar: null,\n                columnNumbers: { ref: 0, start: 1, end: 2 },\n                coordinateType: 'zero-based-half-open',\n                format: 'generic',\n            };\n        const refCount = bytes.readInt32LE(16 + auxLength);\n        // read the indexes for each reference sequence\n        let firstDataLine;\n        let currOffset = 16 + auxLength + 4;\n        const indices = new Array(refCount).fill(0).map(() => {\n            // the binning index\n            const binCount = bytes.readInt32LE(currOffset);\n            currOffset += 4;\n            const binIndex = {};\n            let stats; // < provided by parsing a pseudo-bin, if present\n            for (let j = 0; j < binCount; j += 1) {\n                const bin = bytes.readUInt32LE(currOffset);\n                if (bin > this.maxBinNumber) {\n                    // this is a fake bin that actually has stats information\n                    // about the reference sequence in it\n                    stats = this.parsePseudoBin(bytes, currOffset + 4);\n                    currOffset += 4 + 8 + 4 + 16 + 16;\n                }\n                else {\n                    const loffset = fromBytes(bytes, currOffset + 4);\n                    firstDataLine = this._findFirstData(firstDataLine, loffset);\n                    const chunkCount = bytes.readInt32LE(currOffset + 12);\n                    currOffset += 16;\n                    const chunks = new Array(chunkCount);\n                    for (let k = 0; k < chunkCount; k += 1) {\n                        const u = fromBytes(bytes, currOffset);\n                        const v = fromBytes(bytes, currOffset + 8);\n                        currOffset += 16;\n                        // this._findFirstData(data, u)\n                        chunks[k] = new Chunk(u, v, bin);\n                    }\n                    binIndex[bin] = chunks;\n                }\n            }\n            return { binIndex, stats };\n        });\n        return {\n            ...aux,\n            csi: true,\n            refCount,\n            maxBlockSize: 1 << 16,\n            firstDataLine,\n            csiVersion,\n            indices,\n            depth: this.depth,\n            maxBinNumber: this.maxBinNumber,\n            maxRefLength,\n        };\n    }\n    parsePseudoBin(bytes, offset) {\n        const lineCount = longToNumber(Long.fromBytesLE(bytes.slice(offset + 28, offset + 36), true));\n        return { lineCount };\n    }\n    async blocksForRange(refName, min, max, opts = {}) {\n        if (min < 0) {\n            min = 0;\n        }\n        const indexData = await this.parse(opts);\n        const refId = indexData.refNameToId[refName];\n        if (refId === undefined) {\n            return [];\n        }\n        const ba = indexData.indices[refId];\n        if (!ba) {\n            return [];\n        }\n        // const { linearIndex, binIndex } = indexes\n        const overlappingBins = this.reg2bins(min, max); // List of bin #s that overlap min, max\n        const chunks = [];\n        // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n        for (const [start, end] of overlappingBins) {\n            for (let bin = start; bin <= end; bin++) {\n                if (ba.binIndex[bin]) {\n                    for (const c of ba.binIndex[bin]) {\n                        chunks.push(new Chunk(c.minv, c.maxv, bin));\n                    }\n                }\n            }\n        }\n        return optimizeChunks(chunks, new VirtualOffset(0, 0));\n    }\n    /**\n     * calculate the list of bins that may overlap with region [beg,end) (zero-based half-open)\n     */\n    reg2bins(beg, end) {\n        beg -= 1; // < convert to 1-based closed\n        if (beg < 1) {\n            beg = 1;\n        }\n        if (end > 2 ** 50) {\n            end = 2 ** 34;\n        } // 17 GiB ought to be enough for anybody\n        end -= 1;\n        let l = 0;\n        let t = 0;\n        let s = this.minShift + this.depth * 3;\n        const bins = [];\n        for (; l <= this.depth; s -= 3, t += lshift(1, l * 3), l += 1) {\n            const b = t + rshift(beg, s);\n            const e = t + rshift(end, s);\n            if (e - b + bins.length > this.maxBinNumber) {\n                throw new Error(`query ${beg}-${end} is too large for current binning scheme (shift ${this.minShift}, depth ${this.depth}), try a smaller query or a coarser index binning scheme`);\n            }\n            bins.push([b, e]);\n        }\n        return bins;\n    }\n}\n//# sourceMappingURL=csi.js.map","import AbortablePromiseCache from '@gmod/abortable-promise-cache';\nimport LRU from 'quick-lru';\nimport { Buffer } from 'buffer';\nimport { RemoteFile, LocalFile } from 'generic-filehandle';\nimport { unzip, unzipChunkSlice } from '@gmod/bgzf-filehandle';\nimport { checkAbortSignal } from './util';\nimport TBI from './tbi';\nimport CSI from './csi';\nfunction isASCII(str) {\n    // eslint-disable-next-line no-control-regex\n    return /^[\\u0000-\\u007F]*$/.test(str);\n}\nconst decoder = typeof TextDecoder !== 'undefined' ? new TextDecoder('utf8') : undefined;\nexport default class TabixIndexedFile {\n    /**\n     * @param {object} args\n     *\n     * @param {string} [args.path]\n     *\n     * @param {filehandle} [args.filehandle]\n     *\n     * @param {string} [args.tbiPath]\n     *\n     * @param {filehandle} [args.tbiFilehandle]\n     *\n     * @param {string} [args.csiPath]\n     *\n     * @param {filehandle} [args.csiFilehandle]\n     *\n     * @param {url} [args.url]\n     *\n     * @param {csiUrl} [args.csiUrl]\n     *\n     * @param {tbiUrl} [args.tbiUrl]\n     *\n     * @param {function} [args.renameRefSeqs] optional function with sig `string\n     * => string` to transform reference sequence names for the purpose of\n     * indexing and querying. note that the data that is returned is not altered,\n     * just the names of the reference sequences that are used for querying.\n     */\n    constructor({ path, filehandle, url, tbiPath, tbiUrl, tbiFilehandle, csiPath, csiUrl, csiFilehandle, renameRefSeqs = n => n, chunkCacheSize = 5 * 2 ** 20, }) {\n        if (filehandle) {\n            this.filehandle = filehandle;\n        }\n        else if (path) {\n            this.filehandle = new LocalFile(path);\n        }\n        else if (url) {\n            this.filehandle = new RemoteFile(url);\n        }\n        else {\n            throw new TypeError('must provide either filehandle or path');\n        }\n        if (tbiFilehandle) {\n            this.index = new TBI({\n                filehandle: tbiFilehandle,\n                renameRefSeqs,\n            });\n        }\n        else if (csiFilehandle) {\n            this.index = new CSI({\n                filehandle: csiFilehandle,\n                renameRefSeqs,\n            });\n        }\n        else if (tbiPath) {\n            this.index = new TBI({\n                filehandle: new LocalFile(tbiPath),\n                renameRefSeqs,\n            });\n        }\n        else if (csiPath) {\n            this.index = new CSI({\n                filehandle: new LocalFile(csiPath),\n                renameRefSeqs,\n            });\n        }\n        else if (path) {\n            this.index = new TBI({\n                filehandle: new LocalFile(`${path}.tbi`),\n                renameRefSeqs,\n            });\n        }\n        else if (csiUrl) {\n            this.index = new CSI({\n                filehandle: new RemoteFile(csiUrl),\n            });\n        }\n        else if (tbiUrl) {\n            this.index = new TBI({\n                filehandle: new RemoteFile(tbiUrl),\n            });\n        }\n        else if (url) {\n            this.index = new TBI({\n                filehandle: new RemoteFile(`${url}.tbi`),\n            });\n        }\n        else {\n            throw new TypeError('must provide one of tbiFilehandle, tbiPath, csiFilehandle, csiPath, tbiUrl, csiUrl');\n        }\n        this.renameRefSeq = renameRefSeqs;\n        this.chunkCache = new AbortablePromiseCache({\n            cache: new LRU({ maxSize: Math.floor(chunkCacheSize / (1 << 16)) }),\n            fill: (args, signal) => this.readChunk(args, { signal }),\n        });\n    }\n    /**\n     * @param refName name of the reference sequence\n     *\n     * @param start start of the region (in 0-based half-open coordinates)\n     *\n     * @param end end of the region (in 0-based half-open coordinates)\n     *\n     * @param opts callback called for each line in the region. can also pass a\n     * object param containing obj.lineCallback, obj.signal, etc\n     *\n     * @returns promise that is resolved when the whole read is finished,\n     * rejected on error\n     */\n    async getLines(refName, s, e, opts) {\n        var _a, _b;\n        let signal;\n        let options = {};\n        let callback;\n        if (typeof opts === 'function') {\n            callback = opts;\n        }\n        else {\n            options = opts;\n            callback = opts.lineCallback;\n            signal = opts.signal;\n        }\n        const metadata = await this.index.getMetadata(options);\n        checkAbortSignal(signal);\n        const start = s !== null && s !== void 0 ? s : 0;\n        const end = e !== null && e !== void 0 ? e : metadata.maxRefLength;\n        if (!(start <= end)) {\n            throw new TypeError('invalid start and end coordinates. start must be less than or equal to end');\n        }\n        if (start === end) {\n            return;\n        }\n        const chunks = await this.index.blocksForRange(refName, start, end, options);\n        checkAbortSignal(signal);\n        // now go through each chunk and parse and filter the lines out of it\n        for (const c of chunks) {\n            const { buffer, cpositions, dpositions } = await this.chunkCache.get(c.toString(), c, signal);\n            checkAbortSignal(signal);\n            let blockStart = 0;\n            let pos = 0;\n            const str = (_a = decoder === null || decoder === void 0 ? void 0 : decoder.decode(buffer)) !== null && _a !== void 0 ? _a : buffer.toString();\n            // fast path, Buffer is just ASCII chars and not gigantor, can be\n            // converted to string and processed directly. if it is not ASCII or\n            // gigantic (chrome max str len is 512Mb), we have to decode line by line\n            const strIsASCII = buffer.length < 500000000 && isASCII(str);\n            while (blockStart < str.length) {\n                let line;\n                let n;\n                if (strIsASCII) {\n                    n = str.indexOf('\\n', blockStart);\n                    if (n === -1) {\n                        break;\n                    }\n                    line = str.slice(blockStart, n);\n                }\n                else {\n                    n = buffer.indexOf('\\n', blockStart);\n                    if (n === -1) {\n                        break;\n                    }\n                    const b = buffer.slice(blockStart, n);\n                    line = (_b = decoder === null || decoder === void 0 ? void 0 : decoder.decode(b)) !== null && _b !== void 0 ? _b : b.toString();\n                }\n                // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n                if (dpositions) {\n                    while (blockStart + c.minv.dataPosition >= dpositions[pos++]) { }\n                    pos--;\n                }\n                // filter the line for whether it is within the requested range\n                const { startCoordinate, overlaps } = this.checkLine(metadata, refName, start, end, line);\n                if (overlaps) {\n                    callback(line, \n                    // cpositions[pos] refers to actual file offset of a bgzip block\n                    // boundaries\n                    //\n                    // we multiply by (1 <<8) in order to make sure each block has a\n                    // \"unique\" address space so that data in that block could never\n                    // overlap\n                    //\n                    // then the blockStart-dpositions is an uncompressed file offset\n                    // from that bgzip block boundary, and since the cpositions are\n                    // multiplied by (1 << 8) these uncompressed offsets get a unique\n                    // space\n                    cpositions[pos] * (1 << 8) +\n                        (blockStart - dpositions[pos]) +\n                        c.minv.dataPosition +\n                        1);\n                }\n                else if (startCoordinate !== undefined && startCoordinate >= end) {\n                    // the lines were overlapping the region, but now have stopped, so we\n                    // must be at the end of the relevant data and we can stop processing\n                    // data now\n                    return;\n                }\n                blockStart = n + 1;\n            }\n        }\n    }\n    async getMetadata(opts = {}) {\n        return this.index.getMetadata(opts);\n    }\n    /**\n     * get a buffer containing the \"header\" region of the file, which are the\n     * bytes up to the first non-meta line\n     */\n    async getHeaderBuffer(opts = {}) {\n        const { firstDataLine, metaChar, maxBlockSize } = await this.getMetadata(opts);\n        checkAbortSignal(opts.signal);\n        const maxFetch = ((firstDataLine === null || firstDataLine === void 0 ? void 0 : firstDataLine.blockPosition) || 0) + maxBlockSize;\n        // TODO: what if we don't have a firstDataLine, and the header\n        // actually takes up more than one block? this case is not covered here\n        const buf = await this._readRegion(0, maxFetch, opts);\n        const bytes = await unzip(buf);\n        // trim off lines after the last non-meta line\n        if (metaChar) {\n            // trim backward from the end\n            let lastNewline = -1;\n            const newlineByte = '\\n'.charCodeAt(0);\n            const metaByte = metaChar.charCodeAt(0);\n            for (let i = 0; i < bytes.length; i += 1) {\n                if (i === lastNewline + 1 && bytes[i] !== metaByte) {\n                    break;\n                }\n                if (bytes[i] === newlineByte) {\n                    lastNewline = i;\n                }\n            }\n            return bytes.subarray(0, lastNewline + 1);\n        }\n        return bytes;\n    }\n    /**\n     * get a string containing the \"header\" region of the file, is the portion up\n     * to the first non-meta line\n     *\n     * @returns {Promise} for a string\n     */\n    async getHeader(opts = {}) {\n        const bytes = await this.getHeaderBuffer(opts);\n        return bytes.toString('utf8');\n    }\n    /**\n     * get an array of reference sequence names, in the order in which they occur\n     * in the file. reference sequence renaming is not applied to these names.\n     */\n    async getReferenceSequenceNames(opts = {}) {\n        const metadata = await this.getMetadata(opts);\n        return metadata.refIdToName;\n    }\n    /**\n     * @param {object} metadata metadata object from the parsed index, containing\n     * columnNumbers, metaChar, and format\n     *\n     * @param {string} regionRefName\n     *\n     * @param {number} regionStart region start coordinate (0-based-half-open)\n     *\n     * @param {number} regionEnd region end coordinate (0-based-half-open)\n     *\n     * @param {array[string]} line\n     *\n     * @returns {object} like `{startCoordinate, overlaps}`. overlaps is boolean,\n     * true if line is a data line that overlaps the given region\n     */\n    checkLine(metadata, regionRefName, regionStart, regionEnd, line) {\n        const { columnNumbers, metaChar, coordinateType, format } = metadata;\n        // skip meta lines\n        if (metaChar && line.startsWith(metaChar)) {\n            return { overlaps: false };\n        }\n        // check ref/start/end using column metadata from index\n        let { ref, start, end } = columnNumbers;\n        if (!ref) {\n            ref = 0;\n        }\n        if (!start) {\n            start = 0;\n        }\n        if (!end) {\n            end = 0;\n        }\n        if (format === 'VCF') {\n            end = 8;\n        }\n        const maxColumn = Math.max(ref, start, end);\n        // this code is kind of complex, but it is fairly fast. basically, we want\n        // to avoid doing a split, because if the lines are really long that could\n        // lead to us allocating a bunch of extra memory, which is slow\n        let currentColumnNumber = 1; // cols are numbered starting at 1 in the index metadata\n        let currentColumnStart = 0;\n        let refSeq = '';\n        let startCoordinate = -Infinity;\n        const l = line.length;\n        for (let i = 0; i < l + 1; i++) {\n            if (line[i] === '\\t' || i === l) {\n                if (currentColumnNumber === ref) {\n                    if (this.renameRefSeq(line.slice(currentColumnStart, i)) !==\n                        regionRefName) {\n                        return {\n                            overlaps: false,\n                        };\n                    }\n                }\n                else if (currentColumnNumber === start) {\n                    startCoordinate = parseInt(line.slice(currentColumnStart, i), 10);\n                    // we convert to 0-based-half-open\n                    if (coordinateType === '1-based-closed') {\n                        startCoordinate -= 1;\n                    }\n                    if (startCoordinate >= regionEnd) {\n                        return {\n                            startCoordinate,\n                            overlaps: false,\n                        };\n                    }\n                    if (end === 0 || end === start) {\n                        // if we have no end, we assume the feature is 1 bp long\n                        if (startCoordinate + 1 <= regionStart) {\n                            return {\n                                startCoordinate,\n                                overlaps: false,\n                            };\n                        }\n                    }\n                }\n                else if (format === 'VCF' && currentColumnNumber === 4) {\n                    refSeq = line.slice(currentColumnStart, i);\n                }\n                else if (currentColumnNumber === end) {\n                    // this will never match if there is no end column\n                    const endCoordinate = format === 'VCF'\n                        ? this._getVcfEnd(startCoordinate, refSeq, line.slice(currentColumnStart, i))\n                        : Number.parseInt(line.slice(currentColumnStart, i), 10);\n                    if (endCoordinate <= regionStart) {\n                        return {\n                            overlaps: false,\n                        };\n                    }\n                }\n                currentColumnStart = i + 1;\n                currentColumnNumber += 1;\n                if (currentColumnNumber > maxColumn) {\n                    break;\n                }\n            }\n        }\n        return {\n            startCoordinate,\n            overlaps: true,\n        };\n    }\n    _getVcfEnd(startCoordinate, refSeq, info) {\n        let endCoordinate = startCoordinate + refSeq.length;\n        // ignore TRA features as they specify CHR2 and END as being on a different\n        // chromosome\n        //\n        // if CHR2 is on the same chromosome, still ignore it because there should\n        // be another pairwise feature at the end of this one\n        const isTRA = info.includes('SVTYPE=TRA');\n        if (info[0] !== '.' && !isTRA) {\n            let prevChar = ';';\n            for (let j = 0; j < info.length; j += 1) {\n                if (prevChar === ';' && info.slice(j, j + 4) === 'END=') {\n                    let valueEnd = info.indexOf(';', j);\n                    if (valueEnd === -1) {\n                        valueEnd = info.length;\n                    }\n                    endCoordinate = parseInt(info.slice(j + 4, valueEnd), 10);\n                    break;\n                }\n                prevChar = info[j];\n            }\n        }\n        else if (isTRA) {\n            return startCoordinate + 1;\n        }\n        return endCoordinate;\n    }\n    /**\n     * return the approximate number of data lines in the given reference\n     * sequence\n     *\n     * @param refSeq reference sequence name\n     *\n     * @returns number of data lines present on that reference sequence\n     */\n    async lineCount(refName, opts = {}) {\n        return this.index.lineCount(refName, opts);\n    }\n    async _readRegion(pos, size, opts = {}) {\n        const b = Buffer.alloc(size);\n        const { bytesRead, buffer } = await this.filehandle.read(b, 0, size, pos, opts);\n        return buffer.subarray(0, bytesRead);\n    }\n    /**\n     * read and uncompress the data in a chunk (composed of one or more\n     * contiguous bgzip blocks) of the file\n     */\n    async readChunk(c, opts = {}) {\n        // fetch the uncompressed data, uncompress carefully a block at a time, and\n        // stop when done\n        const data = await this._readRegion(c.minv.blockPosition, c.fetchedSize(), opts);\n        return unzipChunkSlice(data, c);\n    }\n}\n//# sourceMappingURL=tabixIndexedFile.js.map"],"names":["longToNumber","long","AbortError","checkAbortSignal","signal","canMergeBlocks","chunk1","chunk2","optimizeChunks","chunks","lowest","mergedChunks","lastChunk","c0","c1","dif","chunk","VirtualOffset","blockPosition","dataPosition","b","fromBytes","bytes","offset","bigendian","Chunk","minv","maxv","bin","fetchedSize","IndexFile","filehandle","renameRefSeqs","opts","_indices","rest","currentFdl","virtualOffset","e","seqId","_a","TBI_MAGIC","TAD_LIDX_SHIFT","reg2bins","beg","end","TabixIndex","refName","indexData","refId","stats","buf","unzip","refCount","formatFlags","coordinateType","format","columnNumbers","metaValue","depth","maxBinNumber","maxRefLength","metaChar","skipLines","nameSectionLength","refNameToId","refIdToName","currOffset","firstDataLine","binCount","binIndex","j","chunkCount","k","u","v","linearCount","linearIndex","Long","namesBytes","currRefId","currNameStart","i","min","max","ba","overlappingBins","start","c","nintv","minLin","maxLin","vp","CSI1_MAGIC","CSI2_MAGIC","lshift","num","bits","rshift","CSI","args","csiVersion","auxLength","aux","indices","loffset","l","t","bins","isASCII","str","decoder","TabixIndexedFile","path","url","tbiPath","tbiUrl","tbiFilehandle","csiPath","csiUrl","csiFilehandle","n","chunkCacheSize","LocalFile","RemoteFile","TBI","AbortablePromiseCache","LRU","s","_b","options","callback","metadata","buffer","cpositions","dpositions","blockStart","pos","strIsASCII","line","startCoordinate","overlaps","maxBlockSize","maxFetch","lastNewline","newlineByte","metaByte","regionRefName","regionStart","regionEnd","ref","maxColumn","currentColumnNumber","currentColumnStart","refSeq","info","endCoordinate","isTRA","prevChar","valueEnd","size","Buffer","bytesRead","data","unzipChunkSlice"],"mappings":"qJAAO,SAASA,EAAaC,EAAM,CAC/B,GAAIA,EAAK,YAAY,OAAO,gBAAgB,GACxCA,EAAK,SAAS,OAAO,gBAAgB,EACrC,MAAM,IAAI,MAAM,kBAAkB,EAEtC,OAAOA,EAAK,SAAU,CAC1B,CACA,MAAMC,WAAmB,KAAM,CAC/B,CAaO,SAASC,EAAiBC,EAAQ,CACrC,GAAKA,GAGDA,EAAO,QAAS,CAChB,GAAI,OAAO,aAAiB,IACxB,MAAM,IAAI,aAAa,UAAW,YAAY,EAE7C,CACD,MAAM,EAAI,IAAIF,GAAW,SAAS,EAClC,QAAE,KAAO,cACH,CAClB,CACA,CACA,CAWO,SAASG,GAAeC,EAAQC,EAAQ,CAC3C,OAAQA,EAAO,KAAK,cAAgBD,EAAO,KAAK,cAAgB,MAC5DC,EAAO,KAAK,cAAgBD,EAAO,KAAK,cAAgB,GAChE,CACO,SAASE,EAAeC,EAAQC,EAAQ,CAC3C,MAAMC,EAAe,CAAE,EACvB,IAAIC,EAAY,KAChB,OAAIH,EAAO,SAAW,EACXA,GAEXA,EAAO,KAAK,SAAUI,EAAIC,EAAI,CAC1B,MAAMC,EAAMF,EAAG,KAAK,cAAgBC,EAAG,KAAK,cAC5C,OAAOC,IAAQ,EAAIA,EAAMF,EAAG,KAAK,aAAeC,EAAG,KAAK,YAChE,CAAK,EACDL,EAAO,QAAQO,GAAS,EAChB,CAACN,GAAUM,EAAM,KAAK,UAAUN,CAAM,EAAI,KACtCE,IAAc,MACdD,EAAa,KAAKK,CAAK,EACvBJ,EAAYI,GAGRX,GAAeO,EAAWI,CAAK,EAC3BA,EAAM,KAAK,UAAUJ,EAAU,IAAI,EAAI,IACvCA,EAAU,KAAOI,EAAM,OAI3BL,EAAa,KAAKK,CAAK,EACvBJ,EAAYI,GAIhC,CAAK,EACML,EACX,CChFe,MAAMM,CAAc,CAC/B,YAAYC,EAAeC,EAAc,CACrC,KAAK,cAAgBD,EACrB,KAAK,aAAeC,CAC5B,CACI,UAAW,CACP,MAAO,GAAG,KAAK,aAAa,IAAI,KAAK,YAAY,EACzD,CACI,UAAUC,EAAG,CACT,OAAQ,KAAK,cAAgBA,EAAE,eAAiB,KAAK,aAAeA,EAAE,YAC9E,CACA,CACO,SAASC,EAAUC,EAAOC,EAAS,EAAGC,EAAY,GAAO,CAC5D,GAAIA,EACA,MAAM,IAAI,MAAM,iDAAiD,EAErE,OAAO,IAAIP,EAAcK,EAAMC,EAAS,CAAC,EAAI,cACzCD,EAAMC,EAAS,CAAC,EAAI,WACpBD,EAAMC,EAAS,CAAC,EAAI,SACpBD,EAAMC,EAAS,CAAC,EAAI,MACpBD,EAAMC,EAAS,CAAC,EAAI,IACpBD,EAAMC,EAAS,CAAC,EAAID,EAAMC,EAAS,CAAC,GAAK,EAAKD,EAAMC,CAAM,CAAC,CACnE,CCrBe,MAAME,CAAM,CACvB,YAAYC,EAAMC,EAAMC,EAAKC,EAAc,OAAW,CAClD,KAAK,KAAOH,EACZ,KAAK,KAAOC,EACZ,KAAK,IAAMC,EACX,KAAK,aAAeC,CAC5B,CACI,gBAAiB,CACb,MAAO,GAAG,KAAK,IAAI,KAAK,KAAK,IAAI,SAAS,KAAK,GAAG,iBAAiB,KAAK,YAAW,CAAE,GAC7F,CACI,UAAW,CACP,OAAO,KAAK,eAAgB,CACpC,CACI,UAAUT,EAAG,CACT,OAAQ,KAAK,KAAK,UAAUA,EAAE,IAAI,GAC9B,KAAK,KAAK,UAAUA,EAAE,IAAI,GAC1B,KAAK,IAAMA,EAAE,GACzB,CACI,aAAc,CACV,OAAI,KAAK,eAAiB,OACf,KAAK,aAET,KAAK,KAAK,cAAiB,MAAW,KAAK,KAAK,aAC/D,CACA,CCzBe,MAAMU,CAAU,CAC3B,YAAY,CAAE,WAAAC,EAAY,cAAAC,EAAiB,GAAM,CAAC,EAAK,CACnD,KAAK,WAAaD,EAClB,KAAK,aAAeC,CAC5B,CACI,MAAM,YAAYC,EAAO,GAAI,CACzB,KAAM,CAAE,QAASC,EAAU,GAAGC,CAAM,EAAG,MAAM,KAAK,MAAMF,CAAI,EAC5D,OAAOE,CACf,CACI,eAAeC,EAAYC,EAAe,CACtC,OAAID,EACOA,EAAW,UAAUC,CAAa,EAAI,EACvCA,EACAD,EAGCC,CAEnB,CACI,MAAM,MAAMJ,EAAO,GAAI,CACnB,OAAK,KAAK,SACN,KAAK,OAAS,KAAK,OAAOA,CAAI,EAAE,MAAOK,GAAM,CACzC,WAAK,OAAS,OACRA,CACtB,CAAa,GAEE,KAAK,MACpB,CACI,MAAM,UAAUC,EAAON,EAAO,GAAI,CAC9B,IAAIO,EAEJ,MAAO,CAAC,EAAG,GAAAA,GADC,MAAM,KAAK,MAAMP,CAAI,GACb,QAAQM,CAAK,KAAO,MAAQC,IAAO,SAAkBA,EAAG,SACpF,CACA,CC3BA,MAAMC,GAAY,SACZC,EAAiB,GAKvB,SAASC,GAASC,EAAKC,EAAK,CACxB,OAAAD,GAAO,EACPC,GAAO,EACA,CACH,CAAC,EAAG,CAAC,EACL,CAAC,GAAKD,GAAO,IAAK,GAAKC,GAAO,GAAG,EACjC,CAAC,GAAKD,GAAO,IAAK,GAAKC,GAAO,GAAG,EACjC,CAAC,IAAMD,GAAO,IAAK,IAAMC,GAAO,GAAG,EACnC,CAAC,KAAOD,GAAO,IAAK,KAAOC,GAAO,GAAG,EACrC,CAAC,MAAQD,GAAO,IAAK,MAAQC,GAAO,GAAG,CAC1C,CACL,CACe,MAAMC,UAAmBhB,CAAU,CAC9C,MAAM,UAAUiB,EAASd,EAAO,GAAI,CAChC,MAAMe,EAAY,MAAM,KAAK,MAAMf,CAAI,EACjCgB,EAAQD,EAAU,YAAYD,CAAO,EAK3C,GAJIE,IAAU,QAIV,CADQD,EAAU,QAAQC,CAAK,EAE/B,MAAO,GAEX,KAAM,CAAE,MAAAC,CAAO,EAAGF,EAAU,QAAQC,CAAK,EACzC,OAAIC,EACOA,EAAM,UAEV,EACf,CAEI,MAAM,OAAOjB,EAAO,GAAI,CACpB,MAAMkB,EAAM,MAAM,KAAK,WAAW,SAASlB,CAAI,EACzCX,EAAQ,MAAM8B,EAAMD,CAAG,EAG7B,GAFAhD,EAAiB8B,EAAK,MAAM,EAExBX,EAAM,aAAa,CAAC,IAAMmB,GAC1B,MAAM,IAAI,MAAM,gBAAgB,EAIpC,MAAMY,EAAW/B,EAAM,YAAY,CAAC,EAC9BgC,EAAchC,EAAM,YAAY,CAAC,EACjCiC,EAAiBD,EAAc,MAAU,uBAAyB,iBAMlEE,EALa,CACf,EAAG,UACH,EAAG,MACH,EAAG,KACN,EACyBF,EAAc,EAAG,EAC3C,GAAI,CAACE,EACD,MAAM,IAAI,MAAM,qCAAqCF,CAAW,EAAE,EAEtE,MAAMG,EAAgB,CAClB,IAAKnC,EAAM,YAAY,EAAE,EACzB,MAAOA,EAAM,YAAY,EAAE,EAC3B,IAAKA,EAAM,YAAY,EAAE,CAC5B,EACKoC,EAAYpC,EAAM,YAAY,EAAE,EAChCqC,EAAQ,EACRC,IAAiB,IAAOD,EAAQ,GAAK,GAAM,GAAK,EAChDE,EAAe,IAAM,GAAKF,EAAQ,GAClCG,EAAWJ,EAAY,OAAO,aAAaA,CAAS,EAAI,KACxDK,EAAYzC,EAAM,YAAY,EAAE,EAEhC0C,EAAoB1C,EAAM,YAAY,EAAE,EACxC,CAAE,YAAA2C,EAAa,YAAAC,CAAa,EAAG,KAAK,gBAAgB5C,EAAM,MAAM,GAAI,GAAK0C,CAAiB,CAAC,EAEjG,IAAIG,EAAa,GAAKH,EAClBI,EA8CJ,MAAO,CACH,QA9CY,IAAI,MAAMf,CAAQ,EAAE,KAAK,CAAC,EAAE,IAAI,IAAM,CAElD,MAAMgB,EAAW/C,EAAM,YAAY6C,CAAU,EAC7CA,GAAc,EACd,MAAMG,EAAW,CAAE,EACnB,IAAIpB,EACJ,QAASqB,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAAG,CAClC,MAAM3C,EAAMN,EAAM,aAAa6C,CAAU,EAEzC,GADAA,GAAc,EACVvC,EAAMgC,EAAe,EACrB,MAAM,IAAI,MAAM,4DAA4D,EAE3E,GAAIhC,IAAQgC,EAAe,EAAG,CAC/B,MAAMY,EAAalD,EAAM,YAAY6C,CAAU,EAC/CA,GAAc,EACVK,IAAe,IACftB,EAAQ,KAAK,eAAe5B,EAAO6C,CAAU,GAEjDA,GAAc,GAAKK,CACvC,KACqB,CACD,MAAMA,EAAalD,EAAM,YAAY6C,CAAU,EAC/CA,GAAc,EACd,MAAM1D,EAAS,IAAI,MAAM+D,CAAU,EACnC,QAASC,EAAI,EAAGA,EAAID,EAAYC,GAAK,EAAG,CACpC,MAAMC,EAAIrD,EAAUC,EAAO6C,CAAU,EAC/BQ,EAAItD,EAAUC,EAAO6C,EAAa,CAAC,EACzCA,GAAc,GACdC,EAAgB,KAAK,eAAeA,EAAeM,CAAC,EACpDjE,EAAOgE,CAAC,EAAI,IAAIhD,EAAMiD,EAAGC,EAAG/C,CAAG,CACvD,CACoB0C,EAAS1C,CAAG,EAAInB,CACpC,CACA,CAEY,MAAMmE,EAActD,EAAM,YAAY6C,CAAU,EAChDA,GAAc,EACd,MAAMU,EAAc,IAAI,MAAMD,CAAW,EACzC,QAASH,EAAI,EAAGA,EAAIG,EAAaH,GAAK,EAClCI,EAAYJ,CAAC,EAAIpD,EAAUC,EAAO6C,CAAU,EAC5CA,GAAc,EACdC,EAAgB,KAAK,eAAeA,EAAeS,EAAYJ,CAAC,CAAC,EAErE,MAAO,CAAE,SAAAH,EAAU,YAAAO,EAAa,MAAA3B,CAAO,CACnD,CAAS,EAGG,SAAAY,EACA,aAAAF,EACA,aAAAC,EACA,UAAAE,EACA,cAAAK,EACA,cAAAX,EACA,eAAAF,EACA,OAAAC,EACA,YAAAU,EACA,YAAAD,EACA,aAAc,KACjB,CACT,CACI,eAAe3C,EAAOC,EAAQ,CAE1B,MAAO,CAAE,UADSvB,EAAa8E,EAAK,YAAYxD,EAAM,MAAMC,EAAS,GAAIA,EAAS,EAAE,EAAG,EAAI,CAAC,CACxE,CAC5B,CACI,gBAAgBwD,EAAY,CACxB,IAAIC,EAAY,EACZC,EAAgB,EACpB,MAAMf,EAAc,CAAE,EAChBD,EAAc,CAAE,EACtB,QAASiB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,GAAK,EACxC,GAAI,CAACH,EAAWG,CAAC,EAAG,CAChB,GAAID,EAAgBC,EAAG,CACnB,IAAInC,EAAUgC,EAAW,SAAS,OAAQE,EAAeC,CAAC,EAC1DnC,EAAU,KAAK,aAAaA,CAAO,EACnCmB,EAAYc,CAAS,EAAIjC,EACzBkB,EAAYlB,CAAO,EAAIiC,CAC3C,CACgBC,EAAgBC,EAAI,EACpBF,GAAa,CAC7B,CAEQ,MAAO,CAAE,YAAAf,EAAa,YAAAC,CAAa,CAC3C,CACI,MAAM,eAAenB,EAASoC,EAAKC,EAAKnD,EAAO,CAAA,EAAI,CAC3CkD,EAAM,IACNA,EAAM,GAEV,MAAMnC,EAAY,MAAM,KAAK,MAAMf,CAAI,EACjCgB,EAAQD,EAAU,YAAYD,CAAO,EAC3C,GAAIE,IAAU,OACV,MAAO,CAAE,EAEb,MAAMoC,EAAKrC,EAAU,QAAQC,CAAK,EAClC,GAAI,CAACoC,EACD,MAAO,CAAE,GAEKA,EAAG,YAAY,OAC3BA,EAAG,YAAYF,GAAOzC,GAAkB2C,EAAG,YAAY,OACnDA,EAAG,YAAY,OAAS,EACxBF,GAAOzC,CAAc,EACzB,IAAIzB,EAAc,EAAG,CAAC,IAExB,QAAQ,KAAK,0CAA0C,EAG3D,MAAMqE,EAAkB3C,GAASwC,EAAKC,CAAG,EACnC3E,EAAS,CAAE,EAEjB,SAAW,CAAC8E,EAAO1C,CAAG,IAAKyC,EACvB,QAAS1D,EAAM2D,EAAO3D,GAAOiB,EAAKjB,IAC9B,GAAIyD,EAAG,SAASzD,CAAG,EACf,UAAW4D,KAAKH,EAAG,SAASzD,CAAG,EAC3BnB,EAAO,KAAK,IAAIgB,EAAM+D,EAAE,KAAMA,EAAE,KAAM5D,CAAG,CAAC,EAO1D,MAAM6D,EAAQJ,EAAG,YAAY,OAC7B,IAAI3E,EAAS,KACb,MAAMgF,EAAS,KAAK,IAAIP,GAAO,GAAIM,EAAQ,CAAC,EACtCE,EAAS,KAAK,IAAIP,GAAO,GAAIK,EAAQ,CAAC,EAC5C,QAASP,EAAIQ,EAAQR,GAAKS,EAAQ,EAAET,EAAG,CACnC,MAAMU,EAAKP,EAAG,YAAYH,CAAC,EACvBU,IACI,CAAClF,GAAUkF,EAAG,UAAUlF,CAAM,EAAI,KAClCA,EAASkF,EAG7B,CACQ,OAAOpF,EAAeC,EAAQC,CAAM,CAC5C,CACA,CChNA,MAAMmF,GAAa,SACbC,GAAa,SACnB,SAASC,GAAOC,EAAKC,EAAM,CACvB,OAAOD,EAAM,GAAKC,CACtB,CACA,SAASC,EAAOF,EAAKC,EAAM,CACvB,OAAO,KAAK,MAAMD,EAAM,GAAKC,CAAI,CACrC,CACe,MAAME,UAAYrE,CAAU,CACvC,YAAYsE,EAAM,CACd,MAAMA,CAAI,EACV,KAAK,aAAe,EACpB,KAAK,MAAQ,EACb,KAAK,SAAW,CACxB,CACI,MAAM,UAAUrD,EAASd,EAAO,GAAI,CAChC,MAAMe,EAAY,MAAM,KAAK,MAAMf,CAAI,EACjCgB,EAAQD,EAAU,YAAYD,CAAO,EAK3C,GAJIE,IAAU,QAIV,CADQD,EAAU,QAAQC,CAAK,EAE/B,MAAO,GAEX,KAAM,CAAE,MAAAC,CAAO,EAAGF,EAAU,QAAQC,CAAK,EACzC,OAAIC,EACOA,EAAM,UAEV,EACf,CACI,UAAW,CACP,MAAM,IAAI,MAAM,qCAAqC,CAC7D,CACI,aAAa5B,EAAOC,EAAQ,CACxB,MAAM+B,EAAchC,EAAM,YAAYC,CAAM,EACtCgC,EAAiBD,EAAc,MAAU,uBAAyB,iBAClEE,EAAS,CAAE,EAAG,UAAW,EAAG,MAAO,EAAG,KAAK,EAAGF,EAAc,EAAG,EACrE,GAAI,CAACE,EACD,MAAM,IAAI,MAAM,qCAAqCF,CAAW,EAAE,EAEtE,MAAMG,EAAgB,CAClB,IAAKnC,EAAM,YAAYC,EAAS,CAAC,EACjC,MAAOD,EAAM,YAAYC,EAAS,CAAC,EACnC,IAAKD,EAAM,YAAYC,EAAS,EAAE,CACrC,EACKmC,EAAYpC,EAAM,YAAYC,EAAS,EAAE,EACzCuC,EAAWJ,EAAY,OAAO,aAAaA,CAAS,EAAI,KACxDK,EAAYzC,EAAM,YAAYC,EAAS,EAAE,EACzCyC,EAAoB1C,EAAM,YAAYC,EAAS,EAAE,EACjD,CAAE,YAAA2C,EAAa,YAAAD,GAAgB,KAAK,gBAAgB3C,EAAM,MAAMC,EAAS,GAAIA,EAAS,GAAKyC,CAAiB,CAAC,EACnH,MAAO,CACH,YAAAE,EACA,YAAAD,EACA,UAAAF,EACA,SAAAD,EACA,cAAAL,EACA,OAAAD,EACA,eAAAD,CACH,CACT,CACI,gBAAgBwB,EAAY,CACxB,IAAIC,EAAY,EACZC,EAAgB,EACpB,MAAMf,EAAc,CAAE,EAChBD,EAAc,CAAE,EACtB,QAASiB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,GAAK,EACxC,GAAI,CAACH,EAAWG,CAAC,EAAG,CAChB,GAAID,EAAgBC,EAAG,CACnB,IAAInC,EAAUgC,EAAW,SAAS,OAAQE,EAAeC,CAAC,EAC1DnC,EAAU,KAAK,aAAaA,CAAO,EACnCmB,EAAYc,CAAS,EAAIjC,EACzBkB,EAAYlB,CAAO,EAAIiC,CAC3C,CACgBC,EAAgBC,EAAI,EACpBF,GAAa,CAC7B,CAEQ,MAAO,CAAE,YAAAf,EAAa,YAAAC,CAAa,CAC3C,CAEI,MAAM,OAAOjC,EAAO,GAAI,CACpB,MAAMX,EAAQ,MAAM8B,EAAM,MAAM,KAAK,WAAW,SAASnB,CAAI,CAAC,EAE9D,IAAIoE,EACJ,GAAI/E,EAAM,aAAa,CAAC,IAAMuE,GAC1BQ,EAAa,UAER/E,EAAM,aAAa,CAAC,IAAMwE,GAC/BO,EAAa,MAGb,OAAM,IAAI,MAAM,gBAAgB,EAGpC,KAAK,SAAW/E,EAAM,YAAY,CAAC,EACnC,KAAK,MAAQA,EAAM,YAAY,CAAC,EAChC,KAAK,eAAiB,IAAO,KAAK,MAAQ,GAAK,GAAM,GAAK,EAC1D,MAAMuC,EAAe,IAAM,KAAK,SAAW,KAAK,MAAQ,GAClDyC,EAAYhF,EAAM,YAAY,EAAE,EAChCiF,EAAMD,GAAaA,GAAa,GAChC,KAAK,aAAahF,EAAO,EAAE,EAC3B,CACE,YAAa,CAAE,EACf,YAAa,CAAE,EACf,SAAU,KACV,cAAe,CAAE,IAAK,EAAG,MAAO,EAAG,IAAK,CAAG,EAC3C,eAAgB,uBAChB,OAAQ,SACX,EACC+B,EAAW/B,EAAM,YAAY,GAAKgF,CAAS,EAEjD,IAAIlC,EACAD,EAAa,GAAKmC,EAAY,EAClC,MAAME,EAAU,IAAI,MAAMnD,CAAQ,EAAE,KAAK,CAAC,EAAE,IAAI,IAAM,CAElD,MAAMgB,EAAW/C,EAAM,YAAY6C,CAAU,EAC7CA,GAAc,EACd,MAAMG,EAAW,CAAE,EACnB,IAAIpB,EACJ,QAASqB,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAAG,CAClC,MAAM3C,EAAMN,EAAM,aAAa6C,CAAU,EACzC,GAAIvC,EAAM,KAAK,aAGXsB,EAAQ,KAAK,eAAe5B,EAAO6C,EAAa,CAAC,EACjDA,GAAc,OAEb,CACD,MAAMsC,EAAUpF,EAAUC,EAAO6C,EAAa,CAAC,EAC/CC,EAAgB,KAAK,eAAeA,EAAeqC,CAAO,EAC1D,MAAMjC,EAAalD,EAAM,YAAY6C,EAAa,EAAE,EACpDA,GAAc,GACd,MAAM1D,EAAS,IAAI,MAAM+D,CAAU,EACnC,QAASC,EAAI,EAAGA,EAAID,EAAYC,GAAK,EAAG,CACpC,MAAMC,EAAIrD,EAAUC,EAAO6C,CAAU,EAC/BQ,EAAItD,EAAUC,EAAO6C,EAAa,CAAC,EACzCA,GAAc,GAEd1D,EAAOgE,CAAC,EAAI,IAAIhD,EAAMiD,EAAGC,EAAG/C,CAAG,CACvD,CACoB0C,EAAS1C,CAAG,EAAInB,CACpC,CACA,CACY,MAAO,CAAE,SAAA6D,EAAU,MAAApB,CAAO,CACtC,CAAS,EACD,MAAO,CACH,GAAGqD,EACH,IAAK,GACL,SAAAlD,EACA,aAAc,MACd,cAAAe,EACA,WAAAiC,EACA,QAAAG,EACA,MAAO,KAAK,MACZ,aAAc,KAAK,aACnB,aAAA3C,CACH,CACT,CACI,eAAevC,EAAOC,EAAQ,CAE1B,MAAO,CAAE,UADSvB,EAAa8E,EAAK,YAAYxD,EAAM,MAAMC,EAAS,GAAIA,EAAS,EAAE,EAAG,EAAI,CAAC,CACxE,CAC5B,CACI,MAAM,eAAewB,EAASoC,EAAKC,EAAKnD,EAAO,CAAA,EAAI,CAC3CkD,EAAM,IACNA,EAAM,GAEV,MAAMnC,EAAY,MAAM,KAAK,MAAMf,CAAI,EACjCgB,EAAQD,EAAU,YAAYD,CAAO,EAC3C,GAAIE,IAAU,OACV,MAAO,CAAE,EAEb,MAAMoC,EAAKrC,EAAU,QAAQC,CAAK,EAClC,GAAI,CAACoC,EACD,MAAO,CAAE,EAGb,MAAMC,EAAkB,KAAK,SAASH,EAAKC,CAAG,EACxC3E,EAAS,CAAE,EAEjB,SAAW,CAAC8E,EAAO1C,CAAG,IAAKyC,EACvB,QAAS1D,EAAM2D,EAAO3D,GAAOiB,EAAKjB,IAC9B,GAAIyD,EAAG,SAASzD,CAAG,EACf,UAAW4D,KAAKH,EAAG,SAASzD,CAAG,EAC3BnB,EAAO,KAAK,IAAIgB,EAAM+D,EAAE,KAAMA,EAAE,KAAM5D,CAAG,CAAC,EAK1D,OAAOpB,EAAeC,EAAQ,IAAIQ,EAAc,EAAG,CAAC,CAAC,CAC7D,CAII,SAAS2B,EAAKC,EAAK,CACfD,GAAO,EACHA,EAAM,IACNA,EAAM,GAENC,EAAM,GAAK,KACXA,EAAM,GAAK,IAEfA,GAAO,EACP,IAAI6D,EAAI,EACJC,EAAI,EACJ,EAAI,KAAK,SAAW,KAAK,MAAQ,EACrC,MAAMC,EAAO,CAAE,EACf,KAAOF,GAAK,KAAK,MAAO,GAAK,EAAGC,GAAKZ,GAAO,EAAGW,EAAI,CAAC,EAAGA,GAAK,EAAG,CAC3D,MAAMtF,EAAIuF,EAAIT,EAAOtD,EAAK,CAAC,EACrBN,EAAIqE,EAAIT,EAAOrD,EAAK,CAAC,EAC3B,GAAIP,EAAIlB,EAAIwF,EAAK,OAAS,KAAK,aAC3B,MAAM,IAAI,MAAM,SAAShE,CAAG,IAAIC,CAAG,mDAAmD,KAAK,QAAQ,WAAW,KAAK,KAAK,0DAA0D,EAEtL+D,EAAK,KAAK,CAACxF,EAAGkB,CAAC,CAAC,CAC5B,CACQ,OAAOsE,CACf,CACA,CCvNA,SAASC,GAAQC,EAAK,CAElB,MAAO,qBAAqB,KAAKA,CAAG,CACxC,CACA,MAAMC,EAAU,OAAO,YAAgB,IAAc,IAAI,YAAY,MAAM,EAAI,OAChE,MAAMC,EAAiB,CA2BlC,YAAY,CAAE,KAAAC,EAAM,WAAAlF,EAAY,IAAAmF,EAAK,QAAAC,EAAS,OAAAC,EAAQ,cAAAC,EAAe,QAAAC,EAAS,OAAAC,EAAQ,cAAAC,EAAe,cAAAxF,EAAgByF,GAAKA,EAAG,eAAAC,EAAiB,EAAI,GAAK,IAAO,CAC1J,GAAI3F,EACA,KAAK,WAAaA,UAEbkF,EACL,KAAK,WAAa,IAAIU,EAAUV,CAAI,UAE/BC,EACL,KAAK,WAAa,IAAIU,EAAWV,CAAG,MAGpC,OAAM,IAAI,UAAU,wCAAwC,EAEhE,GAAIG,EACA,KAAK,MAAQ,IAAIQ,EAAI,CACjB,WAAYR,EACZ,cAAArF,CAChB,CAAa,UAEIwF,EACL,KAAK,MAAQ,IAAIrB,EAAI,CACjB,WAAYqB,EACZ,cAAAxF,CAChB,CAAa,UAEImF,EACL,KAAK,MAAQ,IAAIU,EAAI,CACjB,WAAY,IAAIF,EAAUR,CAAO,EACjC,cAAAnF,CAChB,CAAa,UAEIsF,EACL,KAAK,MAAQ,IAAInB,EAAI,CACjB,WAAY,IAAIwB,EAAUL,CAAO,EACjC,cAAAtF,CAChB,CAAa,UAEIiF,EACL,KAAK,MAAQ,IAAIY,EAAI,CACjB,WAAY,IAAIF,EAAU,GAAGV,CAAI,MAAM,EACvC,cAAAjF,CAChB,CAAa,UAEIuF,EACL,KAAK,MAAQ,IAAIpB,EAAI,CACjB,WAAY,IAAIyB,EAAWL,CAAM,CACjD,CAAa,UAEIH,EACL,KAAK,MAAQ,IAAIS,EAAI,CACjB,WAAY,IAAID,EAAWR,CAAM,CACjD,CAAa,UAEIF,EACL,KAAK,MAAQ,IAAIW,EAAI,CACjB,WAAY,IAAID,EAAW,GAAGV,CAAG,MAAM,CACvD,CAAa,MAGD,OAAM,IAAI,UAAU,oFAAoF,EAE5G,KAAK,aAAelF,EACpB,KAAK,WAAa,IAAI8F,EAAsB,CACxC,MAAO,IAAIC,EAAI,CAAE,QAAS,KAAK,MAAML,EAAkB,KAAQ,EAAG,EAClE,KAAM,CAACtB,EAAMhG,IAAW,KAAK,UAAUgG,EAAM,CAAE,OAAAhG,EAAQ,CACnE,CAAS,CACT,CAcI,MAAM,SAAS2C,EAASiF,EAAG1F,EAAGL,EAAM,CAChC,IAAIO,EAAIyF,EACR,IAAI7H,EACA8H,EAAU,CAAE,EACZC,EACA,OAAOlG,GAAS,WAChBkG,EAAWlG,GAGXiG,EAAUjG,EACVkG,EAAWlG,EAAK,aAChB7B,EAAS6B,EAAK,QAElB,MAAMmG,EAAW,MAAM,KAAK,MAAM,YAAYF,CAAO,EACrD/H,EAAiBC,CAAM,EACvB,MAAMmF,EAAQyC,GAAiC,EACzCnF,EAAMP,GAAiC8F,EAAS,aACtD,GAAI,EAAE7C,GAAS1C,GACX,MAAM,IAAI,UAAU,4EAA4E,EAEpG,GAAI0C,IAAU1C,EACV,OAEJ,MAAMpC,EAAS,MAAM,KAAK,MAAM,eAAesC,EAASwC,EAAO1C,EAAKqF,CAAO,EAC3E/H,EAAiBC,CAAM,EAEvB,UAAWoF,KAAK/E,EAAQ,CACpB,KAAM,CAAE,OAAA4H,EAAQ,WAAAC,EAAY,WAAAC,CAAU,EAAK,MAAM,KAAK,WAAW,IAAI/C,EAAE,WAAYA,EAAGpF,CAAM,EAC5FD,EAAiBC,CAAM,EACvB,IAAIoI,EAAa,EACbC,EAAM,EACV,MAAM3B,GAAOtE,EAAKuE,GAAY,KAA6B,OAASA,EAAQ,OAAOsB,CAAM,KAAO,MAAQ7F,IAAO,OAASA,EAAK6F,EAAO,SAAU,EAIxIK,EAAaL,EAAO,OAAS,KAAaxB,GAAQC,CAAG,EAC3D,KAAO0B,EAAa1B,EAAI,QAAQ,CAC5B,IAAI6B,EACAlB,EACJ,GAAIiB,EAAY,CAEZ,GADAjB,EAAIX,EAAI,QAAQ;AAAA,EAAM0B,CAAU,EAC5Bf,IAAM,GACN,MAEJkB,EAAO7B,EAAI,MAAM0B,EAAYf,CAAC,CAClD,KACqB,CAED,GADAA,EAAIY,EAAO,QAAQ;AAAA,EAAMG,CAAU,EAC/Bf,IAAM,GACN,MAEJ,MAAMrG,EAAIiH,EAAO,MAAMG,EAAYf,CAAC,EACpCkB,GAAQV,EAAKlB,GAAY,KAA6B,OAASA,EAAQ,OAAO3F,CAAC,KAAO,MAAQ6G,IAAO,OAASA,EAAK7G,EAAE,SAAU,CACnJ,CAEgB,GAAImH,EAAY,CACZ,KAAOC,EAAahD,EAAE,KAAK,cAAgB+C,EAAWE,GAAK,GAAG,CAC9DA,GACpB,CAEgB,KAAM,CAAE,gBAAAG,EAAiB,SAAAC,CAAU,EAAG,KAAK,UAAUT,EAAUrF,EAASwC,EAAO1C,EAAK8F,CAAI,EACxF,GAAIE,EACAV,EAASQ,EAYTL,EAAWG,CAAG,EAAK,KACdD,EAAaD,EAAWE,CAAG,GAC5BjD,EAAE,KAAK,aACP,CAAC,UAEAoD,IAAoB,QAAaA,GAAmB/F,EAIzD,OAEJ2F,EAAaf,EAAI,CACjC,CACA,CACA,CACI,MAAM,YAAYxF,EAAO,GAAI,CACzB,OAAO,KAAK,MAAM,YAAYA,CAAI,CAC1C,CAKI,MAAM,gBAAgBA,EAAO,GAAI,CAC7B,KAAM,CAAE,cAAAmC,EAAe,SAAAN,EAAU,aAAAgF,CAAc,EAAG,MAAM,KAAK,YAAY7G,CAAI,EAC7E9B,EAAiB8B,EAAK,MAAM,EAC5B,MAAM8G,IAAa3E,GAAkB,KAAmC,OAASA,EAAc,gBAAkB,GAAK0E,EAGhH3F,EAAM,MAAM,KAAK,YAAY,EAAG4F,EAAU9G,CAAI,EAC9CX,EAAQ,MAAM8B,EAAMD,CAAG,EAE7B,GAAIW,EAAU,CAEV,IAAIkF,EAAc,GAClB,MAAMC,EAAc,GACdC,EAAWpF,EAAS,WAAW,CAAC,EACtC,QAASoB,EAAI,EAAGA,EAAI5D,EAAM,QAClB,EAAA4D,IAAM8D,EAAc,GAAK1H,EAAM4D,CAAC,IAAMgE,GADZhE,GAAK,EAI/B5D,EAAM4D,CAAC,IAAM+D,IACbD,EAAc9D,GAGtB,OAAO5D,EAAM,SAAS,EAAG0H,EAAc,CAAC,CACpD,CACQ,OAAO1H,CACf,CAOI,MAAM,UAAUW,EAAO,GAAI,CAEvB,OADc,MAAM,KAAK,gBAAgBA,CAAI,GAChC,SAAS,MAAM,CACpC,CAKI,MAAM,0BAA0BA,EAAO,GAAI,CAEvC,OADiB,MAAM,KAAK,YAAYA,CAAI,GAC5B,WACxB,CAgBI,UAAUmG,EAAUe,EAAeC,EAAaC,EAAWV,EAAM,CAC7D,KAAM,CAAE,cAAAlF,EAAe,SAAAK,EAAU,eAAAP,EAAgB,OAAAC,CAAQ,EAAG4E,EAE5D,GAAItE,GAAY6E,EAAK,WAAW7E,CAAQ,EACpC,MAAO,CAAE,SAAU,EAAO,EAG9B,GAAI,CAAE,IAAAwF,EAAK,MAAA/D,EAAO,IAAA1C,CAAK,EAAGY,EACrB6F,IACDA,EAAM,GAEL/D,IACDA,EAAQ,GAEP1C,IACDA,EAAM,GAENW,IAAW,QACXX,EAAM,GAEV,MAAM0G,EAAY,KAAK,IAAID,EAAK/D,EAAO1C,CAAG,EAI1C,IAAI2G,EAAsB,EACtBC,EAAqB,EACrBC,EAAS,GACTd,EAAkB,KACtB,MAAMlC,EAAIiC,EAAK,OACf,QAASzD,EAAI,EAAGA,EAAIwB,EAAI,EAAGxB,IACvB,GAAIyD,EAAKzD,CAAC,IAAM,KAAQA,IAAMwB,EAAG,CAC7B,GAAI8C,IAAwBF,GACxB,GAAI,KAAK,aAAaX,EAAK,MAAMc,EAAoBvE,CAAC,CAAC,IACnDiE,EACA,MAAO,CACH,SAAU,EACb,UAGAK,IAAwBjE,EAAO,CAMpC,GALAqD,EAAkB,SAASD,EAAK,MAAMc,EAAoBvE,CAAC,EAAG,EAAE,EAE5D3B,IAAmB,mBACnBqF,GAAmB,GAEnBA,GAAmBS,EACnB,MAAO,CACH,gBAAAT,EACA,SAAU,EACb,EAEL,IAAI/F,IAAQ,GAAKA,IAAQ0C,IAEjBqD,EAAkB,GAAKQ,EACvB,MAAO,CACH,gBAAAR,EACA,SAAU,EACb,CAG7B,SACyBpF,IAAW,OAASgG,IAAwB,EACjDE,EAASf,EAAK,MAAMc,EAAoBvE,CAAC,UAEpCsE,IAAwB3G,IAEPW,IAAW,MAC3B,KAAK,WAAWoF,EAAiBc,EAAQf,EAAK,MAAMc,EAAoBvE,CAAC,CAAC,EAC1E,OAAO,SAASyD,EAAK,MAAMc,EAAoBvE,CAAC,EAAG,EAAE,IACtCkE,EACjB,MAAO,CACH,SAAU,EACb,EAKT,GAFAK,EAAqBvE,EAAI,EACzBsE,GAAuB,EACnBA,EAAsBD,EACtB,KAEpB,CAEQ,MAAO,CACH,gBAAAX,EACA,SAAU,EACb,CACT,CACI,WAAWA,EAAiBc,EAAQC,EAAM,CACtC,IAAIC,EAAgBhB,EAAkBc,EAAO,OAM7C,MAAMG,EAAQF,EAAK,SAAS,YAAY,EACxC,GAAIA,EAAK,CAAC,IAAM,KAAO,CAACE,EAAO,CAC3B,IAAIC,EAAW,IACf,QAASvF,EAAI,EAAGA,EAAIoF,EAAK,OAAQpF,GAAK,EAAG,CACrC,GAAIuF,IAAa,KAAOH,EAAK,MAAMpF,EAAGA,EAAI,CAAC,IAAM,OAAQ,CACrD,IAAIwF,EAAWJ,EAAK,QAAQ,IAAKpF,CAAC,EAC9BwF,IAAa,KACbA,EAAWJ,EAAK,QAEpBC,EAAgB,SAASD,EAAK,MAAMpF,EAAI,EAAGwF,CAAQ,EAAG,EAAE,EACxD,KACpB,CACgBD,EAAWH,EAAKpF,CAAC,CACjC,CACA,SACiBsF,EACL,OAAOjB,EAAkB,EAE7B,OAAOgB,CACf,CASI,MAAM,UAAU7G,EAASd,EAAO,GAAI,CAChC,OAAO,KAAK,MAAM,UAAUc,EAASd,CAAI,CACjD,CACI,MAAM,YAAYwG,EAAKuB,EAAM/H,EAAO,CAAA,EAAI,CACpC,MAAMb,EAAI6I,EAAAA,OAAO,MAAMD,CAAI,EACrB,CAAE,UAAAE,EAAW,OAAA7B,CAAQ,EAAG,MAAM,KAAK,WAAW,KAAKjH,EAAG,EAAG4I,EAAMvB,EAAKxG,CAAI,EAC9E,OAAOoG,EAAO,SAAS,EAAG6B,CAAS,CAC3C,CAKI,MAAM,UAAU1E,EAAGvD,EAAO,GAAI,CAG1B,MAAMkI,EAAO,MAAM,KAAK,YAAY3E,EAAE,KAAK,cAAeA,EAAE,YAAa,EAAEvD,CAAI,EAC/E,OAAOmI,EAAgBD,EAAM3E,CAAC,CACtC,CACA","x_google_ignoreList":[0,1,2,3,4,5,6]}